TODO notes

Agent:
	Todo next:
	Todo later/maybe:
		- Continue training for another 1000000 frames

Features:
	Todo next:
		- Tune preprocessing and net structure
	Todo later/maybe:
		- predict function to how the features work
		- Batch, instance normalization?

Done:
	- Simple autoencoder
	- Atari Breakout Player
	- Collected frames from trained player or during training

Notes:
	- In breakout, rewards are given at each brocken brick 
	- Normalization and initialization are important for deep nets!
	- Be careful with the loss function for the autoencoder:
		the internal features should be meaningful (i.e. contain fluents).
		Also, do not train the autoencoder alone, but toghether with other losses.
		Use sparsity constraints (regularization loss?) (maybe not necessary with
		binary data) Prefer conv2d maxpooling and upsampling2d
	- Agent training: first improvements seem to show up with
		random < 0.5 and q > 0.7 approx.
