Things TODO:


>Agent:
- Migration:
	- Start writing minimal working example in Trainer
- Add all previous __main__ arguments such as --render, --stream
- Train a good pong agent

>Features:
- predict function to how the features work
- Batch, instance normalization?
- improve initizazion

Things done:
- Simple autoencoder
- Crop the game board to the relevant part
- Tensorforce for DQN
- Trained features and agent on server
- Player.play()
- Decaying exploration rate
- collect training samples during reinforcement learning

Notes:
- In breakout, rewards are given at each brocken brick 
