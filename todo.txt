Things TODO:

>Agent:
- Migration: make the minimal example work with keras-rl
- Add all previous __main__ arguments such as --render, --stream
- Migrate to tf.keras

>Features:
- predict function to how the features work
- Batch, instance normalization?
- improve initizazion

Things done:
- Simple autoencoder
- Crop the game board to the relevant part
- Tensorforce for DQN
- Trained features and agent on server
- Player.play()
- Decaying exploration rate
- collect training samples during reinforcement learning

Notes:
- In breakout, rewards are given at each brocken brick 
