TODO notes

Agent:
	Todo next:
		- Update keras-rl dependencies
		- Retrain, merge
	Todo later/maybe:

Features:
	Todo next:
		- Dataset from streaming player expert
	Todo later/maybe:
		- predict function to how the features work
		- Batch, instance normalization?
		- improve initizazion

Done:
	- Simple autoencoder
	- Collected frames from trained player or during training

Notes:
	- In breakout, rewards are given at each brocken brick 
	- Normalization and initialization are important for deep nets!
	- Be careful with the loss function for the autoencoder:
		the internal features should be meaningful (i.e. contain fluents).
		Also, do not train the autoencoder alone, but toghether with other losses.
		Use sparsity constraints (regularization loss?) (maybe not necessary with
		binary data) Prefer conv2d maxpooling and upsampling2d
	- Agent training: first improvements seem to show up with
		random < 0.5 and q > 0.7 approx.
